{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1128ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "def calculate_ap(retrieved, relevant):\n",
    "    # Initialize variables\n",
    "    precision_at_k = []\n",
    "    num_relevant = len(relevant)\n",
    "    num_retrieved = 0\n",
    "    num_correct = 0\n",
    "    total_sum = 0\n",
    "    \n",
    "    # Calculate precision at each position\n",
    "    for i, item in enumerate(retrieved):\n",
    "        print('I, ITEM', i, item)\n",
    "        \n",
    "        if item in relevant.values:\n",
    "            print('ITEM IS RELEVANT', item)\n",
    "            \n",
    "            num_correct += 1\n",
    "            total_sum = total_sum + num_correct\n",
    "            print(\"total sum final\", total_sum)\n",
    "            precision_at_k.append(num_correct / (i + 1))\n",
    "            num_retrieved += 1\n",
    "    \n",
    "    # Calculate Average Precision (AP)\n",
    "    if num_relevant == 0:\n",
    "        print(\"num relevant 0\", num_relevant)\n",
    "        return 0  # If there are no relevant items for the query, AP is 0\n",
    "    else:\n",
    "        return sum(precision_at_k) / num_relevant\n",
    "\n",
    "def mean_ap(result_df, positive_value):\n",
    "    map_values = list()\n",
    "\n",
    "    groupby_user = result_df.groupby('user')\n",
    "\n",
    "    for user_id in groupby_user.groups.keys():\n",
    "        user_df = groupby_user.get_group(user_id)\n",
    "\n",
    "        relevant_itens = user_df.loc[user_df['rate'] == positive_value]['item']\n",
    "        predictions = user_df.sort_values(by='prediction', ascending=False)\n",
    "        \n",
    "        print('OP', predictions);\n",
    "        print('RELEVANTS', relevant_itens)\n",
    "\n",
    "        ap = calculate_ap(predictions['item'], relevant_itens)\n",
    "        print(\"ap\", ap)\n",
    "        map_values.append(ap)\n",
    "        \n",
    "    print(\"mean results\", sum(map_values), len(groupby_user.groups.keys()))\n",
    "    mean_ap = sum(map_values) / len(groupby_user.groups.keys())\n",
    "    return mean_ap\n",
    "\n",
    "users = [0]\n",
    "items = [2243, 3039, 2577, 3642, 1059, 2917, 5684, 1893, 858, 3404, 4776]\n",
    "rates = [1.0, 1.0, 1.0, 5.0, 1.0, 1.0,  1.0,  1.0,  1.0, 5.0,  1.0 ]\n",
    "predictions = [0.84, 1.26, 1.08, 0.93, 0.95, 1.39, 1.11, 1.07, 0.95, 2.90, 1.01]\n",
    "\n",
    "row_data = []\n",
    "index = 0\n",
    "for u in users:\n",
    "    for i in items:\n",
    "        row_data.append([u, i, rates[index], predictions[index]])\n",
    "        index = index+1\n",
    "\n",
    "test_df = pd.DataFrame(columns=['user', 'item', 'rate', 'prediction'], data=row_data)\n",
    "\n",
    "mean_ap_res = mean_ap(test_df, 5.0)\n",
    "print(\"result\", mean_ap_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b008748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "colnames=['source_document_id', 'recommended_document_id', 'click_count', 'non-click_count'] \n",
    "dataset = pd.read_csv('./data/rard/rating_matrix_fitered.csv', delimiter='\\t', skiprows = 1, names=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60012661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1014a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_score(positivas, negativas):\n",
    "    total_avaliacoes = positivas + negativas\n",
    "    if total_avaliacoes == 0:\n",
    "        return 2.5  # Caso especial quando não há avaliações, pode ser ajustado conforme necessário\n",
    "    if negativas == 0:\n",
    "        return 5\n",
    "    if positivas == 0:\n",
    "        return 1\n",
    "    score = 1 + (positivas - negativas) / total_avaliacoes * 5\n",
    "    return max(1, min(5, score))  # Garante que o resultado esteja dentro da escala 1-5\n",
    "\n",
    "# Exemplo de uso\n",
    "avaliacoes_positivas = 5\n",
    "avaliacoes_negativas = 5\n",
    "\n",
    "score_normalizado = normalize_score(avaliacoes_positivas, avaliacoes_negativas)\n",
    "print(f\"Score Normalizado: {score_normalizado}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ee069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
